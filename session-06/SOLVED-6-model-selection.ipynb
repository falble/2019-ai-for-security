{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model and hyper parameters choice\n",
    "\n",
    "The dataset used in this notebook is the same used in the last two practice sessions: you can copy-paste into the current directory or download it again from [here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).\n",
    "Remember:\n",
    "- you need the kdd.data.gz file\n",
    "- it is a compressed archive, you have to extract it\n",
    "\n",
    "---\n",
    "\n",
    "This session will focus on:\n",
    "- model choice\n",
    "- hyper parameters selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'datasets/kddcup.data.corrected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names obtained from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\n",
    "header_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', \n",
    "    'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', \n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', \n",
    "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', \n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', \n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', \n",
    "    'dst_host_srv_rerror_rate', 'attack_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME, header=None, names=header_names, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "IMPORTANT:\n",
    "    \n",
    "The cell below reduces the size of the dataframe by sampling from it. \n",
    "This is done to work with a smaller amount of data, in case your machine cannot deal with the whole dataset. \n",
    "Try to run the notebook without running this cell but, if you have any problems, come back here, uncomment this line and rerun the whole notebook with less data.\n",
    "</b>\n",
    "\n",
    "If you still have troubles, there is a smaller version available on the same website.\n",
    "The file name is *kddcup.data_10_percent.gz*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the dataset (pt. 1)\n",
    "\n",
    "This is the same dataset we used in the past sessions, but it is useful to recap here some information about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the cells below.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows = 2939059\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows =\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features =\", df.drop('attack_type', axis=1).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the features:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2939059 entries, 578448 to 4164086\n",
      "Data columns (total 42 columns):\n",
      "duration                       int64\n",
      "protocol_type                  object\n",
      "service                        object\n",
      "flag                           object\n",
      "src_bytes                      int64\n",
      "dst_bytes                      int64\n",
      "land                           int64\n",
      "wrong_fragment                 int64\n",
      "urgent                         int64\n",
      "hot                            int64\n",
      "num_failed_logins              int64\n",
      "logged_in                      int64\n",
      "num_compromised                int64\n",
      "root_shell                     int64\n",
      "su_attempted                   int64\n",
      "num_root                       int64\n",
      "num_file_creations             int64\n",
      "num_shells                     int64\n",
      "num_access_files               int64\n",
      "num_outbound_cmds              int64\n",
      "is_host_login                  int64\n",
      "is_guest_login                 int64\n",
      "count                          int64\n",
      "srv_count                      int64\n",
      "serror_rate                    float64\n",
      "srv_serror_rate                float64\n",
      "rerror_rate                    float64\n",
      "srv_rerror_rate                float64\n",
      "same_srv_rate                  float64\n",
      "diff_srv_rate                  float64\n",
      "srv_diff_host_rate             float64\n",
      "dst_host_count                 int64\n",
      "dst_host_srv_count             int64\n",
      "dst_host_same_srv_rate         float64\n",
      "dst_host_diff_srv_rate         float64\n",
      "dst_host_same_src_port_rate    float64\n",
      "dst_host_srv_diff_host_rate    float64\n",
      "dst_host_serror_rate           float64\n",
      "dst_host_srv_serror_rate       float64\n",
      "dst_host_rerror_rate           float64\n",
      "dst_host_srv_rerror_rate       float64\n",
      "attack_type                    object\n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 964.2+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of the features:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 categorical features, and they are:\n",
      "{'protocol_type', 'service', 'flag'}\n"
     ]
    }
   ],
   "source": [
    "set_cat_features = (\n",
    "    set(df.drop('attack_type', axis=1).columns) - set(df.drop('attack_type', axis=1).describe().columns)\n",
    ")\n",
    "print(\"There are %d categorical features, and they are:\" % len(set_cat_features))\n",
    "print(set_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating variables containing indeces of each feature type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = np.array(header_names)\n",
    "\n",
    "nominal_idx = [1, 2, 3]\n",
    "binary_idx = [6, 11, 13, 14, 20, 21]\n",
    "numeric_idx = list(set(range(41)).difference(nominal_idx).difference(binary_idx))\n",
    "\n",
    "nominal_cols = col_names[nominal_idx].tolist()\n",
    "binary_cols = col_names[binary_idx].tolist()\n",
    "numeric_cols = col_names[numeric_idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the dataset (pt. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different 'protocol_type's = 3\n",
      "Number of occurrences of each protocol_type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>icmp</td>\n",
       "      <td>1699093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tcp</td>\n",
       "      <td>1123311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>udp</td>\n",
       "      <td>116655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type      cnt\n",
       "0          icmp  1699093\n",
       "1           tcp  1123311\n",
       "2           udp   116655"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of different 'protocol_type's =\", len(df['protocol_type'].unique()))\n",
    "print(\"Number of occurrences of each protocol_type\")\n",
    "df.groupby('protocol_type').size().reset_index().sort_values(0, ascending=False).rename(columns={0:'cnt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What is the effect of <code>.rename(columns={0:'cnt'})</code>, in the cell above?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Renames the column: from 0 to 'cnt'\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different 'flag's = 11\n",
      "Number of occurrences of each flag\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SF</td>\n",
       "      <td>2246181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S0</td>\n",
       "      <td>522487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REJ</td>\n",
       "      <td>161257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSTR</td>\n",
       "      <td>4802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSTO</td>\n",
       "      <td>3132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SH</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S2</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RSTOS0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTH</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flag      cnt\n",
       "9       SF  2246181\n",
       "5       S0   522487\n",
       "1      REJ   161257\n",
       "4     RSTR     4802\n",
       "2     RSTO     3132\n",
       "10      SH      632\n",
       "6       S1      336\n",
       "7       S2       95\n",
       "3   RSTOS0       77\n",
       "0      OTH       32\n",
       "8       S3       28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of different 'flag's =\", len(df['flag'].unique()))\n",
    "print(\"Number of occurrences of each flag\")\n",
    "df.groupby('flag').size().reset_index().sort_values(0, ascending=False).rename(columns={0:'cnt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different 'service's = 69\n",
      "Number of occurrences of each service\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ecr_i</td>\n",
       "      <td>1685908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>private</td>\n",
       "      <td>660934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>http</td>\n",
       "      <td>374306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>smtp</td>\n",
       "      <td>57940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>other</td>\n",
       "      <td>43555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>domain_u</td>\n",
       "      <td>34662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ftp_data</td>\n",
       "      <td>24537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eco_i</td>\n",
       "      <td>9801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>finger</td>\n",
       "      <td>4149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>urp_i</td>\n",
       "      <td>3277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ftp</td>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>telnet</td>\n",
       "      <td>2547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ntp_u</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auth</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>pop_3</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>time</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>imap4</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>uucp_path</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rje</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>csnet_ns</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ssh</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mtp</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>domain</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>remote_job</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>http_443</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>netbios_ssn</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ctf</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ldap</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>login</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>netbios_ns</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>link</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daytime</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>pop_2</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>uucp</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>nntp</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>vmnet</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>netstat</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hostnames</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>discard</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sql_net</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>klogin</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>efs</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sunrpc</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bgp</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nnsp</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>iso_tsap</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>netbios_dgm</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>exec</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>courier</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kshell</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRC</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>urh_i</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X11</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tim_i</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pm_dump</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>red_i</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>http_8001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tftp_u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>harvest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http_2784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        service      cnt\n",
       "14        ecr_i  1685908\n",
       "48      private   660934\n",
       "23         http   374306\n",
       "53         smtp    57940\n",
       "43        other    43555\n",
       "11     domain_u    34662\n",
       "19     ftp_data    24537\n",
       "13        eco_i     9801\n",
       "17       finger     4149\n",
       "64        urp_i     3277\n",
       "18          ftp     3145\n",
       "59       telnet     2547\n",
       "42        ntp_u     2239\n",
       "3          auth     2052\n",
       "46        pop_3     1156\n",
       "62         time      977\n",
       "27        imap4      689\n",
       "66    uucp_path      667\n",
       "51          rje      665\n",
       "6      csnet_ns      661\n",
       "55          ssh      659\n",
       "34          mtp      657\n",
       "10       domain      657\n",
       "50   remote_job      656\n",
       "25     http_443      655\n",
       "38  netbios_ssn      653\n",
       "7           ctf      653\n",
       "31         ldap      651\n",
       "33        login      651\n",
       "37   netbios_ns      645\n",
       "..          ...      ...\n",
       "32         link      632\n",
       "8       daytime      632\n",
       "45        pop_2      631\n",
       "65         uucp      631\n",
       "41         nntp      628\n",
       "67        vmnet      627\n",
       "39      netstat      625\n",
       "22    hostnames      623\n",
       "9       discard      621\n",
       "54      sql_net      620\n",
       "29       klogin      620\n",
       "15          efs      619\n",
       "56       sunrpc      614\n",
       "4           bgp      613\n",
       "40         nnsp      613\n",
       "28     iso_tsap      612\n",
       "36  netbios_dgm      611\n",
       "16         exec      611\n",
       "5       courier      608\n",
       "30       kshell      601\n",
       "0           IRC      319\n",
       "63        urh_i       98\n",
       "1           X11       83\n",
       "61        tim_i        5\n",
       "44      pm_dump        5\n",
       "49        red_i        4\n",
       "26    http_8001        2\n",
       "60       tftp_u        1\n",
       "21      harvest        1\n",
       "24    http_2784        1\n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of different 'service's =\", len(df['service'].unique()))\n",
    "print(\"Number of occurrences of each service\")\n",
    "df.groupby('service').size().reset_index().sort_values(0, ascending=False).rename(columns={0:'cnt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping each attack type to one category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell modifies the data in the dataframe, if you run it more than once, you might encounter some errors\n",
    "df['attack_type'] = df.apply(lambda r: r['attack_type'][:-1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file *training_attack_types.txt* maps each of the attacks in the original dataset to 1 category.\n",
    "The file can be found [here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html), or you can use the same one you used last time.\n",
    "\n",
    "#### IMPORTANT\n",
    "Check that there are no empty lines at the end of the file, otherwise the code below might not work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = defaultdict(list)\n",
    "category['benign'].append('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ATTACK_TYPES_FILENAME = 'datasets/training_attack_types.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_ATTACK_TYPES_FILENAME, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        attack, cat = line.strip().split(' ')\n",
    "        category[cat].append(attack)\n",
    "\n",
    "attack_mapping = {v: k for k in category for v in category[k]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`attack_mapping`, as created above, is a dictionary that maps each attack_type to one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 categories\n",
      "Their names are: {'dos', 'benign', 'u2r', 'probe', 'r2l'}\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d categories\" % len(set(attack_mapping.values())))\n",
    "print(\"Their names are:\", set(attack_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the cell that performs the actual mapping\n",
    "df['attack_category'] = df.apply(lambda r: attack_mapping[r['attack_type']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This is similar to what was done above. The difference is that here a new column is created (named \"attack_category\"), which contains, for each row, the category of the attack type (<code>r['attack_type']</code> is used as a key to access the dictionary <code>attack_mapping</code>) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of each category:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack_category</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dos</td>\n",
       "      <td>2329516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benign</td>\n",
       "      <td>584332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probe</td>\n",
       "      <td>24501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2l</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u2r</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attack_category        0\n",
       "1             dos  2329516\n",
       "0          benign   584332\n",
       "2           probe    24501\n",
       "3             r2l      679\n",
       "4             u2r       31"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of occurrences of each category:\")\n",
    "df.groupby('attack_category').size().reset_index().sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Looking at the results of the previous cell you should realize that you must be very careful with training a 5-class classifier... Why?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The classes are extremely unbalanced. Thus the model is likely to learn pretty well how to model the most common categories but *not* the least common classes.\n",
    "\n",
    "In case of unbalanced binary classification, a model may learn nothing: in some cases, it always predicts the most common class. It is up to you to detect whether that's the case by looking at the evaluation metrics. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: dummy variables\n",
    "\n",
    "We have some categorical variables. Thus, we have to converte them to one-hot encoded variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Create a new DataFrame encoding the categorical attributes with one hot encoding.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical feature into dummy variables with one-hot encoding\n",
    "df_one_hot = pd.get_dummies(df, columns=nominal_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset up into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_one_hot.drop(['attack_category', 'attack_type'], axis=1), \n",
    "    df_one_hot['attack_category'], \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell might take a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/luca/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/luca/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# if it crashes, you might want to try rerunning the notebook on less data (see df.sample at the beginning)\n",
    "standard_scaler = StandardScaler().fit(X_train[numeric_cols])\n",
    "\n",
    "X_train[numeric_cols] = standard_scaler.transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = standard_scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Why is the scaling performed using the X_train variable only?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Because otherwise you'd be using information about the test set during the training phase: it is a methodological error.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: converting label to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = y_train.apply(lambda x: 0 if x is 'benign' else 1)\n",
    "y_test_bin = y_test.apply(lambda x: 0 if x is 'benign' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMEMBER: `.apply` applies the `lambda` function within the `()` to each element of the sequence (in this case a Series)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6.1 - BINARY CLASSIFICATION\n",
    "\n",
    "Now you have to train a model for performing binary classification (i.e. detecting whether one entry is malicious or not, without caring about the attack_type).\n",
    "\n",
    "You have to perform cross validation and hyperparameters selections in order to find the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First example of Cross Validation with GridSearch\n",
    "\n",
    "The following cell performs hyper parameter selection with 5-fold cross validation.\n",
    "The comments inside this cell should provide enough explanation to let you write the code for performing cross validation on different models and different hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>IMPORTANT</b>: you'll probably notice that some of the combination of parameters take a very long time to run. This is normal and it is due to the fact that, for each possible combination of parameters, the model is trained several times (value set in GridSearchCV). Thus, the elapsed time that you had seen in the previous prac session will get much longer.\n",
    "    \n",
    "You might also have some problems due to memory limitations.\n",
    "As mentioned at the beginning of the notebook, try to sample the original DF or, alternatively, use the 10percent dataset (you can download it from the website).\n",
    "    \n",
    "For this session in the classroom, use small lists of parameters and 2-fold or 3-fold cross validation in order to run the code faster.\n",
    "However, while working at home you have to explore larger choices of hyperparameters and use 5-fold cross validation in order to find better performing models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This line defines the model, in this case a RandomForestClassifier but it could be any classifier (DecisionTreeClassifier, SVC, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this line defines a Pipeline, in this case it is made of only one element and this is what you will need to use for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('clf', classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parameters of the model in the pipeline can be set using `'__'` separated parameter names. In this case, `'clf__n_estimator'` means that the following list is a list of values for the n_estimators attribute of the clf model. Here, it is the number of trees of the RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__n_estimators': [10, 25, 50],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performs cross validation for each of the parameters set above. `cv=3` means that I perform 3-fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'clf__n_estimators': [10, 25, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchRF = GridSearchCV(pipe, param_grid, iid=False, cv=3, verbose=True)\n",
    "searchRF.fit(X_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- once the training is done, you can show the parameters of the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "print(searchRF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- and you can also retrieve it in order to perform the final test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedRF = searchRF.best_estimator_.get_params()['clf']\n",
    "trainedRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = trainedRF.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the following cell in order to perform the final evaluation of the model on the test set.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.999948963273972\n",
      "recall: 0.9999447844682957\n",
      "precision: 0.9999915049059168\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_test_bin, y_pred_RF)) \n",
    "print(\"recall:\", recall_score(y_test_bin, y_pred_RF))\n",
    "print(\"precision:\", precision_score(y_test_bin, y_pred_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example, this time with a DecisionTreeClassifier\n",
    "\n",
    "It is more convenient to write everything in a unique cell, in order to have everything under control.\n",
    "\n",
    "Here I perform 3-fold cross validation on a DecisionTreeClassifier and explore 3 possible values of `max_depth` and 2 possible values of `max_leaf_nodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 10, 'clf__max_leaf_nodes': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', classifier)])\n",
    "\n",
    "# as you can see, you can set lists of value for all the attributes of the model\n",
    "param_grid = {\n",
    "    'clf__max_leaf_nodes': [10, None],\n",
    "    'clf__max_depth': [2, 5, 10],\n",
    "}\n",
    "\n",
    "searchDT = GridSearchCV(pipe, param_grid, iid=False, cv=3, verbose=True)\n",
    "searchDT.fit(X_train, y_train_bin)\n",
    "\n",
    "print(searchDT.best_params_)\n",
    "\n",
    "trainedDT = searchDT.best_estimator_.get_params()['clf']\n",
    "trainedDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = trainedDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the following cell in order to perform the final evaluation of the model on the test set.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.999215735643369\n",
      "recall: 0.9990698306582116\n",
      "precision: 0.9999511124053334\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_test_bin, y_pred_DT)) \n",
    "print(\"recall:\", recall_score(y_test_bin, y_pred_DT))\n",
    "print(\"precision:\", precision_score(y_test_bin, y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"accuracy:\", accuracy_score()) \n",
    "# print(\"recall:\", recall_score())\n",
    "# print(\"precision:\", precision_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Use the scikit-learn Pipeline and GridSearchCV in order to find the best model and hyperparameter configuration. Fill the template below.</b>\n",
    "</div>\n",
    "As mentioned above, keep things simple for this practice session otherwise you won't have time to see the results of the training.\n",
    "\n",
    "Possible models to explore:\n",
    "- GaussianNB\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression\n",
    "- ... but **do** feel free to experiment with other ones as well! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', classifier)])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [25, 50, 75, 100, 125, 150],\n",
    "    'clf__max_depth': [2, 5, 7, 10, 15, 20],\n",
    "    'clf_max_features': ['log2', 'sqrt', None]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=5, verbose=True)\n",
    "search.fit(X_train, y_train_bin)\n",
    "\n",
    "print(search.best_params_)\n",
    "\n",
    "trained_clf = search.best_estimator_.get_params()['clf']\n",
    "trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_clf.predict(X_test)\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(y_test_bin, y_pred)) \n",
    "print(\"recall:\", recall_score(y_test_bin, y_pred))\n",
    "print(\"precision:\", precision_score(y_test_bin, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6.2 - 5-CLASS CLASSIFICATION\n",
    "\n",
    "This last section focuses on performing multiclass classification.\n",
    "Instead of trying to classify each entry as *attack* or *not attack*, we now try to classify it as belonging to one of the following classes:\n",
    "- dos\n",
    "- benign\n",
    "- probe\n",
    "- r2l\n",
    "- u2r\n",
    "\n",
    "Here is an example of model and hyperparameters selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 19.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 10, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('clf', RandomForestClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__max_depth': [2, 5, 10],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=3, verbose=True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(search.best_params_)\n",
    "\n",
    "trained_clf = search.best_estimator_.get_params()['clf']\n",
    "trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9996665600566167\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos\n",
      "{'precision': 0.9999978532618613, 'recall': 0.9999892664014752, 'f1-score': 0.9999935598132346, 'support': 465827}\n",
      "\n",
      "benign\n",
      "{'precision': 0.9983351120597652, 'recall': 1.0, 'f1-score': 0.9991668624895857, 'support': 116930}\n",
      "\n",
      "u2r\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}\n",
      "\n",
      "probe\n",
      "{'precision': 1.0, 'recall': 0.9842985318107668, 'f1-score': 0.9920871441783989, 'support': 4904}\n",
      "\n",
      "r2l\n",
      "{'precision': 1.0, 'recall': 0.2624113475177305, 'f1-score': 0.41573033707865165, 'support': 141}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for attack_type in set(attack_mapping.values()):\n",
    "    print(attack_type)\n",
    "    print(clf_report[attack_type])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Now it's your turn. Experiment with different models, hyperparameters and try to find the best performing model using cross validation with Pipeline and GridSearchCV. Do not forget to tinker with different features as well: as introduced in the last session, try to remove some features, focus only on some features, etc. in order to improve the classification accuracy.\n",
    "    \n",
    "Remember: *one perfect model* to solve this problem does not exist, but by approaching the problem in the correct way, you can get better and better models.\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "Remember, when performing the final evaluation, to look at all the 5 classes and not only at the overall accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Several things you might want to try:\n",
    "    \n",
    "- work on the features: are all of them important? How are they distributed? Does the model gets better if you remove some of the features? etc...\n",
    "\n",
    "- work on the data: is the StandardScaler the best scaler to use? Are the chosen parameters the ones leading to the best result? Should you remove some of the entries of the most common classes in order to focus on the minority classes?\n",
    "\n",
    "- try different models and different hyper parameters for each model (you cannot try \"every\" possible combination, try to pick wisely). For instance, you first do a large grained search and. after that, a fine grained search \"around\" the best parameters. The GridSearchCV might even take hours to run if you set too many parameters; for the sake of this prac session you might want to play with the smaller dataset (10percent)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = ... # feel free to use any models you want\n",
    "\n",
    "# pipe = Pipeline(steps=[('clf', classifier)])\n",
    "\n",
    "# param_grid = {\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# search = GridSearchCV(pipe, param_grid, iid=False, cv=..., verbose=True)\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# print(searchDT.best_params_)\n",
    "\n",
    "# trained_clf = searchDT...\n",
    "# trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = trained_clf..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf_report = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "After you finish the notebook, take a look at this link: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "\n",
    "In the second Section (\"Face recognition with eigenfaces\"), it presents an example of how to use the techniques that you have seen so far in a more challenging problem (face recognition), which is also very relevant from a security perspective, since face recognition is often used for authentication on hand-held devices.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
